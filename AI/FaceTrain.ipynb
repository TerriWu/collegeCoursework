{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceTrain.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PlzwKU_GgwH_","executionInfo":{"status":"ok","timestamp":1659662472121,"user_tz":-480,"elapsed":3463,"user":{"displayName":"Tina Tina","userId":"07701087676874351086"}}},"outputs":[],"source":["import random\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Convolution2D, MaxPooling2D\n","from tensorflow.keras.optimizers import SGD\n","from keras.utils import np_utils\n","from keras.models import load_model\n","from keras import backend as K\n","\n","from FaceNormalization import load_dataset, resize_image, IMAGE_SIZE"]},{"cell_type":"code","source":["class Dataset:\n","    def __init__(self, path_name):\n","        #訓練集\n","        self.train_images = None\n","        self.train_labels = None\n","        \n","        #驗證集\n","        self.valid_images = None\n","        self.valid_labels = None\n","        \n","        #測試集\n","        self.test_images  = None            \n","        self.test_labels  = None\n","        \n","        #資料集載入路徑\n","        self.path_name    = path_name\n","        \n","        #當前庫採用的維度順序\n","        self.input_shape = None\n","        \n","    #載入資料集並按照交叉驗證的原則劃分資料集並進行相關預處理工作\n","    def load(self, img_rows = IMAGE_SIZE, img_cols = IMAGE_SIZE, \n","             img_channels = 3, nb_classes = 2):\n","        #載入資料集到記憶體\n","        images, labels = load_dataset(self.path_name)        \n","        \n","        train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))        \n","        _, test_images, _, test_labels = train_test_split(images, labels, test_size = 0.5, random_state = random.randint(0, 100))                \n","        \n","        #當前的維度順序如果為'th'，則輸入圖片資料時的順序為：channels,rows,cols，否則:rows,cols,channels\n","        #這部分程式碼就是根據keras庫要求的維度順序重組訓練資料集\n","\n","        # if K.image_dim_ordering() == 'th':\n","        if K.image_data_format() == \"channels_first\":\n","\n","            train_images = train_images.reshape(train_images.shape[0], img_channels, img_rows, img_cols)\n","            valid_images = valid_images.reshape(valid_images.shape[0], img_channels, img_rows, img_cols)\n","            test_images = test_images.reshape(test_images.shape[0], img_channels, img_rows, img_cols)\n","            self.input_shape = (img_channels, img_rows, img_cols)            \n","        else:\n","            train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)\n","            valid_images = valid_images.reshape(valid_images.shape[0], img_rows, img_cols, img_channels)\n","            test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)\n","            self.input_shape = (img_rows, img_cols, img_channels)            \n","            \n","            #輸出訓練集、驗證集、測試集的數量\n","            print(train_images.shape[0], 'train samples')\n","            print(valid_images.shape[0], 'valid samples')\n","            print(test_images.shape[0], 'test samples')\n","        \n","            #我們的模型使用categorical_crossentropy作為損失函式，因此需要根據類別數量nb_classes將\n","            #類別標籤進行one-hot編碼使其向量化，在這裡我們的類別只有兩種，經過轉化後標籤資料變為二維\n","            train_labels = np_utils.to_categorical(train_labels, nb_classes)                        \n","            valid_labels = np_utils.to_categorical(valid_labels, nb_classes)            \n","            test_labels = np_utils.to_categorical(test_labels, nb_classes)                        \n","        \n","            #畫素資料浮點化以便歸一化\n","            train_images = train_images.astype('float32')            \n","            valid_images = valid_images.astype('float32')\n","            test_images = test_images.astype('float32')\n","            \n","            #將其歸一化,影象的各畫素值歸一化到0~1區間\n","            train_images /= 255\n","            valid_images /= 255\n","            test_images /= 255            \n","        \n","            self.train_images = train_images\n","            self.valid_images = valid_images\n","            self.test_images  = test_images\n","            self.train_labels = train_labels\n","            self.valid_labels = valid_labels\n","            self.test_labels  = test_labels"],"metadata":{"id":"myXBzmMWg5Zz","executionInfo":{"status":"ok","timestamp":1659662478652,"user_tz":-480,"elapsed":268,"user":{"displayName":"Tina Tina","userId":"07701087676874351086"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#CNN網路模型類            \n","class Model:\n","    def __init__(self):\n","        self.model = None\n","        \n","    #建立模型\n","    def build_model(self, dataset, nb_classes = 2):\n","        #構建一個空的網路模型，它是一個線性堆疊模型，各神經網路層會被順序新增，專業名稱為序貫模型或線性堆疊模型\n","        self.model = Sequential() \n","        \n","        #以下程式碼將順序新增CNN網路需要的各層，一個add就是一個網路層\n","        self.model.add(Convolution2D(32, (3,3), padding='same', \n","                                     input_shape = dataset.input_shape))    #1 2維卷積層\n","        self.model.add(Activation('relu'))                                  #2 啟用函式層\n","        \n","        self.model.add(Convolution2D(32, (3,3)))                             #3 2維卷積層                             \n","        self.model.add(Activation('relu'))                                  #4 啟用函式層\n","        \n","        self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #5 池化層\n","        self.model.add(Dropout(0.25))                                       #6 Dropout層\n","\n","        self.model.add(Convolution2D(64, (3,3)))         #7  2維卷積層\n","        self.model.add(Activation('relu'))                                  #8  啟用函式層\n","        \n","        self.model.add(Convolution2D(64, (3,3)))                             #9  2維卷積層\n","        self.model.add(Activation('relu'))                                  #10 啟用函式層\n","        \n","        self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #11 池化層\n","        self.model.add(Dropout(0.25))                                       #12 Dropout層\n","\n","        self.model.add(Flatten())                                           #13 Flatten層\n","        self.model.add(Dense(512))                                          #14 Dense層,又被稱作全連線層\n","        self.model.add(Activation('relu'))                                  #15 啟用函式層   \n","        self.model.add(Dropout(0.5))                                        #16 Dropout層\n","        self.model.add(Dense(nb_classes))                                   #17 Dense層\n","        self.model.add(Activation('softmax'))                               #18 分類層，輸出最終結果\n","\n","        #輸出模型概況\n","        self.model.summary()\n","        \n","    #訓練模型\n","    def train(self, dataset, batch_size = 20, nb_epoch = 10, data_augmentation = True):        \n","        sgd = SGD(lr = 0.01, decay = 1e-6, \n","                  momentum = 0.9, nesterov = True) #採用SGD+momentum的優化器進行訓練，首先生成一個優化器物件  \n","        self.model.compile(loss='categorical_crossentropy',\n","                           optimizer=sgd,\n","                           metrics=['accuracy'])   #完成實際的模型配置工作\n","        \n","        #不使用資料提升，所謂的提升就是從我們提供的訓練資料中利用旋轉、翻轉、加噪聲等方法創造新的\n","        #訓練資料，有意識的提升訓練資料規模，增加模型訓練量\n","        if not data_augmentation:            \n","            self.model.fit(dataset.train_images,\n","                           dataset.train_labels,\n","                           batch_size = batch_size,\n","                           nb_epoch = nb_epoch,\n","                           validation_data = (dataset.valid_images, dataset.valid_labels),\n","                           shuffle = True)\n","        #使用實時資料提升\n","        else:            \n","            #定義資料生成器用於資料提升，其返回一個生成器物件datagen，datagen每被呼叫一\n","            #次其生成一組資料（順序生成），節省記憶體，其實就是python的資料生成器\n","            datagen = ImageDataGenerator(\n","                featurewise_center = False,             #是否使輸入資料去中心化（均值為0），\n","                samplewise_center  = False,             #是否使輸入資料的每個樣本均值為0\n","                featurewise_std_normalization = False,  #是否資料標準化（輸入資料除以資料集的標準差）\n","                samplewise_std_normalization  = False,  #是否將每個樣本資料除以自身的標準差\n","                zca_whitening = False,                  #是否對輸入資料施以ZCA白化\n","                rotation_range = 20,                    #資料提升時圖片隨機轉動的角度(範圍為0～180)\n","                width_shift_range  = 0.2,               #資料提升時圖片水平偏移的幅度（單位為圖片寬度的佔比，0~1之間的浮點數）\n","                height_shift_range = 0.2,               #同上，只不過這裡是垂直\n","                horizontal_flip = True,                 #是否進行隨機水平翻轉\n","                vertical_flip = False)                  #是否進行隨機垂直翻轉\n","\n","            #計算整個訓練樣本集的數量以用於特徵值歸一化、ZCA白化等處理\n","            datagen.fit(dataset.train_images)                        \n","\n","            #利用生成器開始訓練模型\n","            self.model.fit_generator(datagen.flow(dataset.train_images, dataset.train_labels,\n","                                                   batch_size = batch_size),\n","                                     steps_per_epoch = dataset.train_images.shape[0],\n","                                     epochs = nb_epoch)    \n","    \n","    MODEL_PATH = \"./model/Niaws_model.h5\"\n","    def save_model(self, file_path = MODEL_PATH):\n","         self.model.save(file_path)\n"," \n","    def load_model(self, file_path = MODEL_PATH):\n","         self.model = load_model(file_path)\n","\n","    def evaluate(self, dataset):\n","         score = self.model.evaluate(dataset.test_images, dataset.test_labels, verbose = 1)\n","         print(\"%s: %.2f%%\" % (self.model.metrics_names[1], score[1] * 100))\n","\n","    #識別人臉\n","    def face_predict(self, image):    \n","        #依然是根據後端系統確定維度順序\n","        # if K.image_dim_ordering() == 'th' and image.shape != (1, 3, IMAGE_SIZE, IMAGE_SIZE):\n","        if K.image_data_format() == \"channels_first\" and image.shape != (1, 3, IMAGE_SIZE, IMAGE_SIZE):\n","            image = resize_image(image)                             #尺寸必須與訓練集一致都應該是IMAGE_SIZE x IMAGE_SIZE\n","            image = image.reshape((1, 3, IMAGE_SIZE, IMAGE_SIZE))   #與模型訓練不同，這次只是針對1張圖片進行預測    \n","        # elif K.image_dim_ordering() == 'tf' and image.shape != (1, IMAGE_SIZE, IMAGE_SIZE, 3):\n","        elif image.shape != (1, IMAGE_SIZE, IMAGE_SIZE, 3):\n","            image = resize_image(image)\n","            image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))                    \n","        \n","        #浮點並歸一化\n","        image = image.astype('float32')\n","        image /= 255\n","        \n","        #給出輸入屬於各個類別的概率，我們是二值類別，則該函式會給出輸入影象屬於0和1的概率各為多少\n","        result = self.model.predict(image)\n","        predict_classes=np.argmax(result,axis=1)\n","        print(predict_classes)\n","\n","        #返回類別預測結果\n","        return predict_classes[0]"],"metadata":{"id":"vYK4uHwnhIH-","executionInfo":{"status":"ok","timestamp":1659663841823,"user_tz":-480,"elapsed":263,"user":{"displayName":"Tina Tina","userId":"07701087676874351086"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset = Dataset(\"./source/\")\n","dataset.load()\n","\n","mdl = Model()\n","mdl.build_model(dataset)\n","mdl.train(dataset)\n","mdl.save_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oE5QBGaEhRoU","outputId":"49badd86-e2c4-47c1-f8d3-dd53d1e4d8c9","executionInfo":{"status":"ok","timestamp":1659663879419,"user_tz":-480,"elapsed":1649,"user":{"displayName":"Tina Tina","userId":"07701087676874351086"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(66, 64, 64, 3)\n","46 train samples\n","20 valid samples\n","33 test samples\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           (None, 64, 64, 32)        896       \n","                                                                 \n"," activation_6 (Activation)   (None, 64, 64, 32)        0         \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 62, 62, 32)        9248      \n","                                                                 \n"," activation_7 (Activation)   (None, 62, 62, 32)        0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_3 (Dropout)         (None, 31, 31, 32)        0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 29, 29, 64)        18496     \n","                                                                 \n"," activation_8 (Activation)   (None, 29, 29, 64)        0         \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 27, 27, 64)        36928     \n","                                                                 \n"," activation_9 (Activation)   (None, 27, 27, 64)        0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 13, 13, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 13, 13, 64)        0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 10816)             0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               5538304   \n","                                                                 \n"," activation_10 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_5 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 2)                 1026      \n","                                                                 \n"," activation_11 (Activation)  (None, 2)                 0         \n","                                                                 \n","=================================================================\n","Total params: 5,604,898\n","Trainable params: 5,604,898\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"]},{"output_type":"stream","name":"stdout","text":[" 1/46 [..............................] - ETA: 34s - loss: 0.7357 - accuracy: 0.1667WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 460 batches). You may need to use the repeat() function when building your dataset.\n","46/46 [==============================] - 1s 1ms/step - loss: 0.5196 - accuracy: 0.8261\n"]}]}]}